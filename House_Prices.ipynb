{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Sale Prices with Python\n",
    "Kyle Schmidt\n",
    "December 2019\n",
    "\n",
    "## 1. Introduction\n",
    "The [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) Kaggle competition provides a data set with 79 variables describing houses sold in Ames, Iowa. Sale prices are provided for half of the data to train a regression algorithm and sale prices are withheld on the other half for testing. After creating an algorithm and predicitng the house sale prices on the test data set, submissions are stored in csv format, uploaded to kaggle and scored with the root mean square error (rmse). The methods and processes in this Jupyter notebook resulted in a rmse score of 0.12402 placing me in the top 8% of all submissions.\n",
    "\n",
    "My approach to the problem starts with exploring the data to get a better understanding of the size and types af variables I'm working with and to look for any potential problems with the data. After better understanding the data I move into pre-processing where I address issues with the data and prep the data for modeling. Once pre-processing is complete I use a stack of Ridge, Lasso, Elastic Net, XGBoost and Light Gradient Boosting regression techniques to maximize performance without overfitting.\n",
    "\n",
    "## 2. Data Exploration\n",
    "Data exploration is an important in the process of writing a regression algorithm. Understanding the data and the types of data you will be working with helps identify potential problems, issues and opportunities within the data.\n",
    "\n",
    "### 2.1 Loading the required packages and importing the data\n",
    "Before starting work on this data set I need to import data and packages into my workspace. Much of the work will be done using Pandas and Numpy with the help of several tools from sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "# Load the data. Make sure to update the file paths to where you stored the data,\n",
    "train = pd.read_csv('.../train.csv', delimiter=',')\n",
    "test = pd.read_csv('.../test.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exploration\n",
    "I'll begin by looking at the amount of data, types of data and a smalle sample of each table (train and test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:\n",
      "(1460, 81)\n",
      "---\n",
      "Test data shape:\n",
      "(1459, 80)\n",
      "\n",
      "Train data types:\n",
      "Id                 int64\n",
      "MSSubClass         int64\n",
      "MSZoning          object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "                  ...   \n",
      "MoSold             int64\n",
      "YrSold             int64\n",
      "SaleType          object\n",
      "SaleCondition     object\n",
      "SalePrice          int64\n",
      "Length: 81, dtype: object\n",
      "---\n",
      "Test data types:\n",
      "Id                 int64\n",
      "MSSubClass         int64\n",
      "MSZoning          object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "                  ...   \n",
      "MiscVal            int64\n",
      "MoSold             int64\n",
      "YrSold             int64\n",
      "SaleType          object\n",
      "SaleCondition     object\n",
      "Length: 80, dtype: object\n",
      "\n",
      "Train data sample:\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "---\n",
      "Test data sample:\n",
      "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
      "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
      "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
      "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
      "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
      "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
      "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
      "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
      "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
      "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
      "\n",
      "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0       0      6    2010        WD         Normal  \n",
      "1   12500      6    2010        WD         Normal  \n",
      "2       0      3    2010        WD         Normal  \n",
      "3       0      6    2010        WD         Normal  \n",
      "4       0      1    2010        WD         Normal  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the data shapes.\n",
    "print('Train data shape:')\n",
    "print(train.shape)\n",
    "print('---')\n",
    "print('Test data shape:')\n",
    "print(test.shape)\n",
    "print('')\n",
    "\n",
    "# Print the data types\n",
    "print('Train data types:')\n",
    "print(train.dtypes)\n",
    "print('---')\n",
    "print('Test data types:')\n",
    "print(test.dtypes)\n",
    "print('')\n",
    "\n",
    "# Print a few rows of both data sets\n",
    "print('Train data sample:')\n",
    "print(train.head(5))\n",
    "print('---')\n",
    "print('Test data sample:')\n",
    "print(test.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data has one more column than the test, which is dependant variable. Otherwise the data sets have the same columns and are close to the same size. There is a mix of categorical and numeric data. Some of the categorical data is ordinal and some is not.\n",
    "\n",
    "It's obvious that the data needs some work, here is what I see right now:\n",
    "\n",
    "* The Id column is just a counter and is not needed.\n",
    "* Some of the categorical data is represented numerically. This might be okay if it is ordinal, but requires follow up.\n",
    "* Some of the categorical data is ordinal and needs to be encoded.\n",
    "* There is missing data.\n",
    "* There are a couple combo-features that may be useful.\n",
    "\n",
    "I will need to address each of these data issues. I'll delete the Id column now then work on imputing the missing data before addressing the other issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the unnecessary Id column from both data sets\n",
    "del train['Id']\n",
    "del test['Id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 The target variable\n",
    "The target variable, SalePrice, is a discrete numerical value. I'll look at the distribution of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create histogram of sales prices.\n",
    "plt.hist(train['SalePrice'], bins=30)\n",
    "plt.title('Distribution of Sale Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is a bit right skewed. A skewed distribution can make any outliers have too much influence and reduce the accuracy of the model. I'll perform a lof-transformation on the target variable to make the distribution more normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new column in the train data set for a log transformation of SalePrice\n",
    "train['LogSalePrice'] = np.log(train['SalePrice'])\n",
    "\n",
    "# Create histogram of Log sales prices to see the new distribution.\n",
    "plt.hist(train['LogSalePrice'], bins=30)\n",
    "plt.title('Distribution of Log Sale Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution looks much more normal than the original. To make sure it actually is normal I will create a Q-Q plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-3.30513952, -3.04793228, -2.90489705, ...,  2.90489705,\n",
       "          3.04793228,  3.30513952]),\n",
       "  array([10.46024211, 10.47194981, 10.54270639, ..., 13.34550693,\n",
       "         13.5211395 , 13.53447303])),\n",
       " (0.3982622308161888, 12.024050901109383, 0.9953761475636613))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Q-Q plot to test for normality of the distribution\n",
    "stats.probplot(train['LogSalePrice'], dist=\"norm\", plot=plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Q-Q plot, the distribution is normal. I will continue my regression using the LogSalePrice, and will delete the SalePrice from my dataset. With a Log transform my regression algorithm will give me LogSalePrice as an output so I'll need to remember to transform those values back to SalePrice before submission.\n",
    "\n",
    "There looks to be some departures from normality at the ends of the Q-Q plot line so I'll check for outliers using a z-score test.\n",
    "\n",
    "The z-score gives an observation's position in relation to the mean of the values in terms of standard deviations. A z-score of 0 means the observation is right at the mean and a z-score of 1 means that observation is 1 standard deviation above the mean. According to the 68-95-99.7 rule, 99.7% of the values will be within 3 standard deviations of the mean for a normal distribution.\n",
    "\n",
    "I will consider any observation more than 3 standard deviations from the mean an outlier and remove it form the data. In order to determine which observations are outliers I'll write a short function to identify the outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.596634733096073, 13.226723392728571, 10.460242108190519, 10.578979797857352, 13.534473028231162, 13.275827535915461, 13.323926946863102, 10.47194980911048, 10.542706391070517, 13.229567991666638, 13.345506928718539, 13.521139497361697]\n"
     ]
    }
   ],
   "source": [
    "# Delete original SalePrice column from the train dataset\n",
    "del train['SalePrice']\n",
    "\n",
    "# create a function to perform a z-test and returns any outliers.\n",
    "def z_outlier(array):\n",
    "    \"\"\"takes an array of numbers calculates the z-score and returns the numbers with a z-score greater than 3\"\"\"\n",
    "    array_mean = np.mean(array)\n",
    "    std_dev = np.std(array)\n",
    "    outliers = []\n",
    "    for i in array:\n",
    "        if ((i - array_mean)/std_dev) > 3:\n",
    "            outliers.append(i)\n",
    "        elif ((i - array_mean)/std_dev) < -3:\n",
    "            outliers.append(i)\n",
    "    return outliers\n",
    "\n",
    "# Save outliers in list\n",
    "outl = z_outlier(train['LogSalePrice'])\n",
    "print(outl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-score test has identified 12 outliers. I'll remove these outliers from the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outliers from the train data set\n",
    "for outlier in outl:\n",
    "    train = train[train.LogSalePrice != outlier]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with my exploration of the data I want to look at how each feature correlates to the target value. Before creating the correlation matrix there are 3 combination features I want to create.\n",
    "\n",
    "Several of the features, to me, seem like one feature broken down into several sub categories. When I shop for a house I look at the number of bathrooms - I don't look at the number of bathrooms by floor so it makes sense to me that a single feature for number of bathrooms would be more valuable than individual features for bathroom location. The 3 new features will be TotalSF, TotalBath and YrFromRemod, representing the total square footage, total number of bathrooms and number of years from the last remodel (using 2011 as the year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 bew combo features in both the train and test data sets: TotalSF, YrFromRemod and TotalBath representing\n",
    "# the total square footage of the house, the number of years since the last remodel and the total number of\n",
    "# bathrooms.\n",
    "# Train data\n",
    "train['TotalSF'] = train['TotalBsmtSF'] + train['1stFlrSF'] + train['2ndFlrSF']\n",
    "\n",
    "train['YrFromRemod'] = (2011 - train['YearRemodAdd'])\n",
    "\n",
    "train['TotalBath'] = train['BsmtFullBath'] + (train['BsmtHalfBath']/2) + train['FullBath'] \\\n",
    "+ (train['HalfBath']/2)\n",
    "\n",
    "# Test data\n",
    "test['TotalSF'] = test['TotalBsmtSF'] + test['1stFlrSF'] + test['2ndFlrSF']\n",
    "\n",
    "test['YrFromRemod'] = (2011 - test['YearRemodAdd'])\n",
    "\n",
    "test['TotalBath'] = test['BsmtFullBath'] + (test['BsmtHalfBath']/2) + test['FullBath'] \\\n",
    "+ (test['HalfBath']/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With my new features added to the dataset I'll look at how each feature correlates to the LogSalePrice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass      -0.081231\n",
      "LotFrontage      0.335597\n",
      "LotArea          0.253800\n",
      "OverallQual      0.808986\n",
      "OverallCond     -0.049543\n",
      "YearBuilt        0.586730\n",
      "YearRemodAdd     0.563476\n",
      "MasVnrArea       0.415172\n",
      "BsmtFinSF1       0.355864\n",
      "BsmtFinSF2      -0.001230\n",
      "BsmtUnfSF        0.218351\n",
      "TotalBsmtSF      0.596140\n",
      "1stFlrSF         0.577144\n",
      "2ndFlrSF         0.306183\n",
      "LowQualFinSF    -0.039650\n",
      "GrLivArea        0.687467\n",
      "BsmtFullBath     0.239638\n",
      "BsmtHalfBath    -0.016183\n",
      "FullBath         0.582427\n",
      "HalfBath         0.305932\n",
      "BedroomAbvGr     0.192054\n",
      "KitchenAbvGr    -0.154976\n",
      "TotRmsAbvGrd     0.514748\n",
      "Fireplaces       0.481892\n",
      "GarageYrBlt      0.541007\n",
      "GarageCars       0.674320\n",
      "GarageArea       0.644909\n",
      "WoodDeckSF       0.333106\n",
      "OpenPorchSF      0.350378\n",
      "EnclosedPorch   -0.143931\n",
      "3SsnPorch        0.058304\n",
      "ScreenPorch      0.115038\n",
      "PoolArea         0.039009\n",
      "MiscVal         -0.020830\n",
      "MoSold           0.076677\n",
      "YrSold          -0.037880\n",
      "LogSalePrice     1.000000\n",
      "TotalSF          0.766893\n",
      "YrFromRemod     -0.563476\n",
      "TotalBath        0.664563\n",
      "Name: LogSalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate correlations and print correlations to the target variable\n",
    "target_corr = train.corr()\n",
    "print(target_corr['LogSalePrice'].head(80))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the things you normally look for when house shopping: lot size, house square footage, number of bathrooms and overall quality are most highly correlated to the sale price.\n",
    "\n",
    "The 3 combination features I created all look to have somewhat high correlations to the LogSalePrice.\n",
    "\n",
    "If I was writing the regression model by hand this might be a good moment to think about feature selection and possibly removing some variables from the dataset. With Machine learning I am allowing the model to do the feature selection for me, so it is unnecessary in this setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Pre-Processing\n",
    "Now that I have a better understanding of the types of data I am working with, I can start preparing the data for model building. With machine learning the variables need to be put in a format that the computer can understand. This process involves cleaning, encoding and tranforming the data. I have already identified a few issues to work on so I'll start with data cleaning.\n",
    "\n",
    "### 3.1 Missing data\n",
    "I previously identified that the data sets have missing data. First I'll look to see what is missing and how much of it is missing, then determine how to approach the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing data:\n",
      "PoolQC          1442\n",
      "MiscFeature     1394\n",
      "Alley           1358\n",
      "Fence           1171\n",
      "FireplaceQu      685\n",
      "LotFrontage      259\n",
      "GarageCond        78\n",
      "GarageYrBlt       78\n",
      "GarageType        78\n",
      "GarageFinish      78\n",
      "GarageQual        78\n",
      "BsmtExposure      37\n",
      "BsmtFinType2      37\n",
      "BsmtQual          36\n",
      "BsmtCond          36\n",
      "BsmtFinType1      36\n",
      "MasVnrArea         8\n",
      "MasVnrType         8\n",
      "Electrical         1\n",
      "BldgType           0\n",
      "dtype: int64\n",
      "---\n",
      "Test missing data:\n",
      "PoolQC          1456\n",
      "MiscFeature     1408\n",
      "Alley           1352\n",
      "Fence           1169\n",
      "FireplaceQu      730\n",
      "LotFrontage      227\n",
      "GarageQual        78\n",
      "GarageCond        78\n",
      "GarageFinish      78\n",
      "GarageYrBlt       78\n",
      "GarageType        76\n",
      "BsmtCond          45\n",
      "BsmtExposure      44\n",
      "BsmtQual          44\n",
      "BsmtFinType1      42\n",
      "BsmtFinType2      42\n",
      "MasVnrType        16\n",
      "MasVnrArea        15\n",
      "MSZoning           4\n",
      "BsmtFullBath       2\n",
      "BsmtHalfBath       2\n",
      "TotalBath          2\n",
      "Functional         2\n",
      "Utilities          2\n",
      "GarageCars         1\n",
      "Exterior1st        1\n",
      "TotalSF            1\n",
      "SaleType           1\n",
      "KitchenQual        1\n",
      "BsmtFinSF1         1\n",
      "BsmtFinSF2         1\n",
      "BsmtUnfSF          1\n",
      "TotalBsmtSF        1\n",
      "Exterior2nd        1\n",
      "GarageArea         1\n",
      "LotArea            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify the missing data\n",
    "train_mis = train.isnull().sum().sort_values(ascending=False)\n",
    "test_mis = test.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print('Train missing data:')\n",
    "print(train_mis.head(20))\n",
    "print('---')\n",
    "print('Test missing data:')\n",
    "print(test_mis.head(36))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of missing data. For PoolQC 99% is missing!\n",
    "\n",
    "A quick look at the data_description.txt file that comes with the data shows that an NA in PoolQC actually means that the house doesn't have a pool. None' would be more appropriate than NA because 0 is different than \"I don't know\". This same thing applies to several other variables.\n",
    "\n",
    "Additionally, several variables use NA when 0 would be more approriate. I'll start data imputation by correcting these issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing data:\n",
      "LotFrontage    259\n",
      "Electrical       1\n",
      "BsmtCond         0\n",
      "dtype: int64\n",
      "---\n",
      "Test missing data:\n",
      "LotFrontage     227\n",
      "MSZoning          4\n",
      "TotalBath         2\n",
      "Utilities         2\n",
      "Functional        2\n",
      "Exterior2nd       1\n",
      "KitchenQual       1\n",
      "Exterior1st       1\n",
      "SaleType          1\n",
      "TotalSF           1\n",
      "BsmtFinType2      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create lists of variables where NA's are to be replaced by either 'None' or 0.\n",
    "none_fill = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageQual', 'GarageCond', 'GarageFinish',\n",
    "             'GarageType', 'BsmtExposure', 'BsmtQual', 'BsmtCond', 'MasVnrType']\n",
    "\n",
    "zero_fill = ['GarageYrBlt', 'BsmtFinType2', 'BsmtFinType1', 'MasVnrArea', 'GarageCars', 'GarageArea', 'BsmtFinSF1',\n",
    "             'BsmtFinSF2', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "\n",
    "# Replace NAs with appropriate 'None' or 0\n",
    "for var in none_fill:\n",
    "    train[var] = train[var].fillna('None')\n",
    "    test[var] = test[var].fillna('None')\n",
    "    \n",
    "for var in zero_fill:\n",
    "    train[var] = train[var].fillna(0)\n",
    "    test[var] = test[var].fillna(0)\n",
    "    \n",
    "# Re-assess the staus of missing values\n",
    "train_mis = train.isnull().sum().sort_values(ascending=False)\n",
    "test_mis = test.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print('Train missing data:')\n",
    "print(train_mis.head(3))\n",
    "print('---')\n",
    "print('Test missing data:')\n",
    "print(test_mis.head(11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That fixed the majority of the issues. LotFrontage is the largest of the remaining missing values. I spent some time looking at the data and found that the LotFrontage value is very similar for houses within each neighborhood. For the missing LotFrontage values I will impute the median LotFrontage for the neighborhood in which the house resides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing data:\n",
      "Electrical    1\n",
      "RoofStyle     0\n",
      "dtype: int64\n",
      "---\n",
      "Test missing data:\n",
      "MSZoning        4\n",
      "TotalBath       2\n",
      "Functional      2\n",
      "Utilities       2\n",
      "SaleType        1\n",
      "KitchenQual     1\n",
      "Exterior2nd     1\n",
      "TotalSF         1\n",
      "Exterior1st     1\n",
      "BsmtFinType1    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median LotFrontage, grouped by neighborhood, then impute the missing LotFrontage values.\n",
    "train['LotFrontage'] = train.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "test['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Re-assess the staus of missing values\n",
    "train_mis = train.isnull().sum().sort_values(ascending=False)\n",
    "test_mis = test.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print('Train missing data:')\n",
    "print(train_mis.head(2))\n",
    "print('---')\n",
    "print('Test missing data:')\n",
    "print(test_mis.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now down to just a handful of missing values. These will need to be assessed one-by-one.\n",
    "\n",
    "Electrical:\n",
    "\n",
    "The missing elecrtical value is for a house built in 2006. All houses in the data set built after 1965 have 'SBrkr' electrical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Electrical'] = train['Electrical'].fillna('SBrkr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSZoning:\n",
    "\n",
    "For zoning the same reasoning I used for LotFrontage holds true - neighborhoods tend to have the same zoning. The only difference is I will use mode, rather than median since it's categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['MSZoning'] = test.groupby('Neighborhood')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functional:\n",
    "\n",
    "94% of the data in the test set has a Functional classification of Typ and there weren't any obvious ways to group the non-Typ homes so I will impute Typ for these missing vlaues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 'Typ' for missing Functional values\n",
    "test['Functional'] = test['Functional'].fillna('Typ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilites:\n",
    "\n",
    "There is only one category in this field and only 2 observations that have NA. This variable will not have any predictive power in a model so I will just delete Utilities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the 'Utilities' variable from both the train and test data sets\n",
    "del train['Utilities']\n",
    "del test['Utilities']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior1st:\n",
    "\n",
    "We have just one observation missing this variable. The home with the missing variable was built in 1940, remodeled in 2007 and is in the Edwards neighborhood. I don't see any obvious correlations between any of these variables and Exterior1st so I will impute the most common variable in this field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the mode of the 'Exterior1st' variable for the missing value\n",
    "test['Exterior1st'] = test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SaleType:\n",
    "\n",
    "There is a single SaleType variable missing. I do not see any obvious relationships between this and any other variables so I will impute the mode of the SaleType variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the mode of the 'SaleType' variable for the missing value\n",
    "test['SaleType'] = test['SaleType'].fillna(test['SaleType'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exterior2nd:\n",
    "\n",
    "The single missing observation for this variable is the same observation that was missing the Exterior1st variable. I will use the same technique for imputation on this variable as I did with Exterior1st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the mode of the 'Exterior2nd' variable for the missing value\n",
    "test['Exterior2nd'] = test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KitchenQual:\n",
    "\n",
    "This is another single missing observation. I will impute the mode of the KitchenQual variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the mode of the 'KitchenQual' variable for the missing value\n",
    "test['KitchenQual'] = test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TotalBath and TotalSF:\n",
    "\n",
    "These are two of the combination features I had made. They are missing becuase I created these features before imputing the 0's in for NA's on some of the data. I just need to re-run the same code that created the features in the first place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing data:\n",
      "TotalBath      0\n",
      "RoofMatl       0\n",
      "Exterior2nd    0\n",
      "MasVnrType     0\n",
      "MasVnrArea     0\n",
      "dtype: int64\n",
      "---\n",
      "Test missing data:\n",
      "TotalBath      0\n",
      "CentralAir     0\n",
      "Exterior1st    0\n",
      "Exterior2nd    0\n",
      "MasVnrType     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Re-run the code to create the missing combination features\n",
    "test['TotalSF'] = test['TotalBsmtSF'] + test['1stFlrSF'] + test['2ndFlrSF']\n",
    "\n",
    "test['TotalBath'] = test['BsmtFullBath'] + (test['BsmtHalfBath']/2) + test['FullBath'] \\\n",
    "+ (test['HalfBath']/2)\n",
    "\n",
    "# Re-assess the staus of missing values\n",
    "train_mis = train.isnull().sum().sort_values(ascending=False)\n",
    "test_mis = test.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print('Train missing data:')\n",
    "print(train_mis.head(5))\n",
    "print('---')\n",
    "print('Test missing data:')\n",
    "print(test_mis.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ordinal data\n",
    "Now that missing data is taken care of I can move on to makeing sure the different types of data are in the correct format.\n",
    "\n",
    "Ordinal data is treated differently from other categorical data because, as the name implies, the order of the data gives us additional information. I am going to encode the ordinal data so that we retain that additional information once I start making my model.\n",
    "\n",
    "During data examination I mentioned there is some categorical data that is represented numerically. I will convert these to string data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the numerically represented categorical data\n",
    "numcat = ['MSSubClass','MoSold', 'YrSold']\n",
    "\n",
    "# Change the data type to string for each numerically represented ordinal data\n",
    "for var in numcat:\n",
    "    train[var] = train[var].apply(str)\n",
    "    test[var] = test[var].apply(str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding ordinal data assigns a number to each category. Since order matters I'll need to do this manually rather than letting the computer do it. If I were to use something like the sklearn ordinal encoder it would just apply a 1 to the first category it came across, then a 2 to the next and so on. This would screw up the order of the ordinal categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map ordered values to associated number\n",
    "ordinal_map = {\n",
    "    'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtQual': {'None': 1, 'Po':2, 'Fa': 3, 'TA': 4, 'Gd': 5, 'Ex': 6},\n",
    "    'BsmtCond': {'None': 1, 'Po':2, 'Fa': 3, 'TA': 4, 'Gd': 5, 'Ex': 6},\n",
    "    'BsmtExposure': {'None': 1, 'No': 2, 'Mn': 3, 'Av': 4, 'Gd': 5},\n",
    "    'BsmtFinType1': {'None': 1, 'Unf': 2, 'LwQ': 3, 'Rec': 4, 'BLQ': 5, 'ALQ': 6, 'GLQ': 7},\n",
    "    'BsmtFinType2': {'None': 1, 'Unf': 2, 'LwQ': 3, 'Rec': 4, 'BLQ': 5, 'ALQ': 6, 'GLQ': 7},\n",
    "    'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'CentralAir': {'N': 1, 'Y': 2},\n",
    "    'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'Functional': {'Sal': 1, 'Sev': 2, 'Maj2': 3, 'Maj1': 4, 'Mod': 5, 'Min2': 6, 'Min1': 7, 'Typ': 8},\n",
    "    'FireplaceQu': {'None': 1, 'Po':2, 'Fa': 3, 'TA': 4, 'Gd': 5, 'Ex': 6},\n",
    "    'GarageFinish': {'None': 1, 'Unf': 2, 'RFn': 3, 'Fin': 4},\n",
    "    'GarageQual': {'None': 1, 'Po':2, 'Fa': 3, 'TA': 4, 'Gd': 5, 'Ex': 6},\n",
    "    'GarageCond': {'None': 1, 'Po':2, 'Fa': 3, 'TA': 4, 'Gd': 5, 'Ex': 6},\n",
    "    'PoolQC': {'None': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    }\n",
    "\n",
    "# replace the ordinal values with the new values\n",
    "train.replace(ordinal_map, inplace=True)\n",
    "test.replace(ordinal_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Categorical data\n",
    "The non-ordinal categorical variables need to be encoded as well. Order is not important for the non-ordinal categorical data so I can treat it differently from the ordinal data. I will be one-hot encoding the categorical data. One-hot encoding creates a column for each category and has a binary indicator (0 or 1) on each observation for each category. One-hot encoding allows us to translate string categories (human readable) into numerical categories (computer readable) without implying an order to the categories.\n",
    "\n",
    "To one-hot encode the categorical variables I need to do a few things. First I need to combine the train and test data sets. If I were to one hot encode the data sets separately I would likely get a different number of columns and different column positions.The order which the categories appear in each dataset are different and all of the variables aren't present in both data sets. Before I can combine the datasets I need to remove the LogSalePrice dependant variable from the train data set so the train and test data have the same number of columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data shape:\n",
      "(2907, 81)\n"
     ]
    }
   ],
   "source": [
    "# Seperate the dependant variable from the train data\n",
    "train_y = train.pop('LogSalePrice')\n",
    "\n",
    "# Combine the train and test data\n",
    "all_data = pd.concat(objs=[train, test], axis=0)\n",
    "\n",
    "# View the size of the new data set\n",
    "print('all_data shape:')\n",
    "print(all_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the train and test data combined, I need to separate the numerical and ordinal data from the categorical data. I do not want to one-hot encode the ordinal or numerical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_all_data shape:\n",
      "(2907, 50)\n",
      "---\n",
      "cat_all_data shape:\n",
      "(2907, 31)\n"
     ]
    }
   ],
   "source": [
    "# Separate categorical and numerical data\n",
    "num_all_data = all_data.select_dtypes(include=[np.number])\n",
    "cat_all_data = all_data.select_dtypes(exclude=[np.number])\n",
    "\n",
    "# View the shape of the new data sets\n",
    "print('num_all_data shape:')\n",
    "print(num_all_data.shape)\n",
    "print('---')\n",
    "print('cat_all_data shape:')\n",
    "print(cat_all_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the train and test data combined and the numerical and categorical variables separated I can one-hot encode the categorical variables using pandas.get_dummies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_all_data shape\n",
      "(2907, 226)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "cat_all_data = pd.get_dummies(cat_all_data)\n",
    "\n",
    "# View new data shape\n",
    "print('cat_all_data shape')\n",
    "print(cat_all_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding made the dataset much larger. I went from 31 categorical variables to 226. Some of the variables are very sparse in usage. I'm going to remove those with fewer than 15 observations (used on fewer than ~0.5% of observations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_all_data shape:\n",
      "(2907, 172)\n"
     ]
    }
   ],
   "source": [
    "# Delete columns with fewer than 15 observations\n",
    "for var in list(cat_all_data.columns.values):\n",
    "    if cat_all_data[var].sum() < 15:\n",
    "        del cat_all_data[var]\n",
    "        \n",
    "print('cat_all_data shape:')\n",
    "print(cat_all_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Numerical data\n",
    "Lastly, I'll be transforming the numeric data to a standarized format. Standardization takes each numerical variables and makes the mean of the those values 0 and the standard deviation 1. This puts all of the numeric values on the same scale. Standardization makes sense because we don't really care about what scale the values are on and it's a bit easier to have all the varibales on the same scale, while retaining their variance in relation to the other values.\n",
    "\n",
    "Right now my numeric dataset includes the ordinal data. I do not want to standardize the ordinal data because the standardization would be meaningless - with ordinal data the only thing that matters is the rank. After separating my ordinal data from my numeric, I'll standardize the numeric data and rebind the data together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of the ordinal data\n",
    "ord_all_data = num_all_data.filter(items=ordinal_map.keys())\n",
    "\n",
    "# Make list of numerical column headers\n",
    "num_cols = list(num_all_data.columns.values) - ordinal_map.keys()\n",
    "\n",
    "# Make df of only the numerical data\n",
    "num_all_data = num_all_data.filter(items=num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is separated, so now to standardize the numerical data I'll use sklearn standard scaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_all_data shape:\n",
      "(2907, 36)\n",
      "---\n",
      "   YearBuilt  WoodDeckSF  GrLivArea  HalfBath  EnclosedPorch  BsmtHalfBath  \\\n",
      "0   1.047503   -0.740977   0.427202  1.233699      -0.359345     -0.249490   \n",
      "1   0.154989    1.615832  -0.474595 -0.755410      -0.359345      3.825049   \n",
      "2   0.981390   -0.740977   0.580185  1.233699      -0.359345     -0.249490   \n",
      "3  -1.861429   -0.740977   0.441292 -0.755410       3.872831     -0.249490   \n",
      "4   0.948334    0.777504   1.409516  1.233699      -0.359345     -0.249490   \n",
      "\n",
      "   1stFlrSF  OpenPorchSF  BsmtFullBath  MasVnrArea  ...  PoolArea  BsmtFinSF1  \\\n",
      "0 -0.777076     0.204751      1.086972    0.543534  ... -0.060481    0.588350   \n",
      "1  0.266946    -0.704969     -0.818835   -0.570713  ... -0.060481    1.189439   \n",
      "2 -0.612501    -0.078605      1.086972    0.350246  ... -0.060481    0.102175   \n",
      "3 -0.507070    -0.182999      1.086972   -0.570713  ... -0.060481   -0.494494   \n",
      "4 -0.033918     0.547759      1.086972    1.419013  ... -0.060481    0.475646   \n",
      "\n",
      "   TotRmsAbvGrd  BsmtUnfSF  3SsnPorch  TotalBath  ScreenPorch  LotFrontage  \\\n",
      "0      0.999716  -0.934224  -0.103546   1.594707      -0.2852    -0.207996   \n",
      "1     -0.286202  -0.628959  -0.103546   0.352028      -0.2852     0.485351   \n",
      "2     -0.286202  -0.287245  -0.103546   1.594707      -0.2852    -0.069327   \n",
      "3      0.356757  -0.045766  -0.103546  -0.269311      -0.2852    -0.439112   \n",
      "4      1.642675  -0.159671  -0.103546   1.594707      -0.2852     0.670243   \n",
      "\n",
      "   OverallCond  YrFromRemod  \n",
      "0    -0.510545    -0.897335  \n",
      "1     2.186284     0.396804  \n",
      "2    -0.510545    -0.849404  \n",
      "3    -0.510545     0.684390  \n",
      "4    -0.510545    -0.753542  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the numerical data\n",
    "scaler = StandardScaler()\n",
    "scaled_num_data = scaler.fit_transform(num_all_data)\n",
    "\n",
    "# Output is a numpy array and I want a pandas df. I'll first extract the column headers, then convert the numpyp\n",
    "# array to a pandas df then add the column headers back in\n",
    "col_names = list(num_all_data.columns.values)\n",
    "num_all_data = pd.DataFrame(scaled_num_data)\n",
    "num_all_data.columns = col_names\n",
    "\n",
    "# View a sample of the standardized data\n",
    "print('num_all_data shape:')\n",
    "print(num_all_data.shape)\n",
    "print('---')\n",
    "print(num_all_data.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Finalizing Pre-processing\n",
    "I am almost ready to build the model, but before I do that I need to combine all the columns back together, check for high levels of covariation among variables and remove any highly correlated variables and re-separate the train and test sets.\n",
    "\n",
    "I'll start this process by putting the ordinal and numerical data back together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_all_data shape:\n",
      "(2907, 36)\n",
      "---\n",
      "ord_all_data shape:\n",
      "(2907, 14)\n",
      "---\n",
      "cat_all_data shape:\n",
      "(2907, 172)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# make sure the data sets all have the same number of rows\n",
    "print('num_all_data shape:')\n",
    "print(num_all_data.shape)\n",
    "print('---')\n",
    "print('ord_all_data shape:')\n",
    "print(ord_all_data.shape)\n",
    "print('---')\n",
    "print('cat_all_data shape:')\n",
    "print(cat_all_data.shape)\n",
    "print('---')\n",
    "\n",
    "# The row indices need to be reset for pd.concat to work\n",
    "num_all_data.reset_index(drop=True, inplace=True)\n",
    "ord_all_data.reset_index(drop=True, inplace=True)\n",
    "cat_all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine the numeric and ordinal data sets\n",
    "numord = pd.concat([num_all_data, ord_all_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll check for covariation. I want to remove variables that very high levels of covariance but I want to put a little bit of thought into it. For instance in image classification each feature is a pixel and neighboring pixels will likely be highly correlated, but removing that many features would wreck your model.\n",
    "\n",
    "I am going to look at the highly correlated variables and think about why they are highly correlated. If the variables represent the same underlying information then they are likely just doubling the power of a single piece of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YrFromRemod   YearRemodAdd   -1.000000\n",
      "YearRemodAdd  YrFromRemod    -1.000000\n",
      "KitchenQual   YrFromRemod    -0.612569\n",
      "YrFromRemod   KitchenQual    -0.612569\n",
      "YearBuilt     YrFromRemod    -0.609985\n",
      "YrFromRemod   YearBuilt      -0.609985\n",
      "ExterQual     YrFromRemod    -0.606265\n",
      "YrFromRemod   ExterQual      -0.606265\n",
      "              OverallQual    -0.569073\n",
      "OverallQual   YrFromRemod    -0.569073\n",
      "dtype: float64\n",
      "---\n",
      "PoolQC        PoolQC          1.000000\n",
      "GarageYrBlt   GarageCond      0.949011\n",
      "GarageArea    GarageCars      0.888818\n",
      "TotalSF       GrLivArea       0.862508\n",
      "FireplaceQu   Fireplaces      0.861641\n",
      "TotalSF       TotalBsmtSF     0.826535\n",
      "GrLivArea     TotRmsAbvGrd    0.807864\n",
      "1stFlrSF      TotalBsmtSF     0.797300\n",
      "TotalSF       1stFlrSF        0.789505\n",
      "BsmtFinType2  BsmtFinSF2      0.766760\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create correlation matrix and check for high correlations\n",
    "correl = numord.corr().unstack().sort_values()\n",
    "correl_rev = numord.corr().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "print(correl.head(10))\n",
    "print('---')\n",
    "print(correl_rev.head(10))\n",
    "\n",
    "# Delete highly correlated features\n",
    "del numord['YearRemodAdd']\n",
    "del numord['GarageYrBlt']\n",
    "del numord['GarageArea']\n",
    "del numord['GrLivArea']\n",
    "del numord['FireplaceQu']\n",
    "del numord['TotalBsmtSF']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found 6 pairs of highly correlated variables that seemed to represent the same underlying data. For example GarageYrBlt and GarageCond both are likely descriptive of the condition of the garage. I chose to delete GarageYrBlt because it has a lower correlation value to LogSalePrice than GarageCond.\n",
    "\n",
    "Now I just need to add the categorical data back in, separate the train and test set and I am ready to build my model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproc_all_data shape:\n",
      "(2907, 216)\n",
      "---\n",
      "preproc_train shape:\n",
      "(1448, 216)\n",
      "---\n",
      "preproc_test shape:\n",
      "(1459, 216)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Combine the numerical, ordinal and categorical features\n",
    "preproc_all_data = pd.concat([numord, cat_all_data], axis=1)\n",
    "\n",
    "# Print new data set shape\n",
    "print('preproc_all_data shape:')\n",
    "print(preproc_all_data.shape)\n",
    "print('---')\n",
    "\n",
    "# Re-separate the train and test sets\n",
    "preproc_train = preproc_all_data[:len(train)]\n",
    "preproc_test = preproc_all_data[len(train):]\n",
    "\n",
    "# Check shape to make sure the sets were separated correctly\n",
    "print('preproc_train shape:')\n",
    "print(preproc_train.shape)\n",
    "print('---')\n",
    "print('preproc_test shape:')\n",
    "print(preproc_test.shape)\n",
    "print('---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building\n",
    "I'll be stacking several regression methods (Ridge, Lasso, Elastic Net, XGBoost and Light Gradient Boosting) to try and get the best results without overfitting. \n",
    "\n",
    "Regression stacking takes several models, such as the five I'm using, makes predictions using each model then creates a new dataset of those predicitons. The dataset made up of those predictions is then put through a secondary regressor to get the final results. regression stacking is very computationally heavy so it is best used on smaller datasets.\n",
    "\n",
    "I'll be using k-fold cross validation with k=10 to evaluate and compare each model and I'll use the best performing model as the secondary regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation method\n",
    "kfold = KFold(n_splits = 10, shuffle=True, random_state=1951)\n",
    "\n",
    "# The competition is on the RMSE so I'll create a function to get the CV RSME\n",
    "def cv_rmse(reg_mod, x, y):\n",
    "    return np.sqrt(-cross_val_score(reg_mod, x, y, scoring=\"neg_mean_squared_error\", cv=kfold))\n",
    "\n",
    "# Define the alphas to test\n",
    "rr_alphas = np.linspace(14, 16, 21)\n",
    "las_alphas = np.linspace(0.0001, 0.001, 10)\n",
    "enet_alphas = np.linspace(0.0001, 0.001, 10)\n",
    "\n",
    "\n",
    "# Create model pipelines\n",
    "rr = make_pipeline(RidgeCV(alphas=rr_alphas, cv=kfold))\n",
    "\n",
    "lasso = make_pipeline(LassoCV(max_iter=10000, alphas=las_alphas, random_state=1951, cv=kfold))\n",
    "\n",
    "enet = make_pipeline(ElasticNetCV(max_iter=10000, alphas=enet_alphas, cv=kfold))\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=3000, max_depth=3, min_child_weight=1, subsample=0.75, colsample_bytree=0.5,\n",
    "                   nthread=-1, random_state=1951, objective='reg:squarederror')\n",
    "\n",
    "lgbm = LGBMRegressor(num_leaves=6, learning_rate=0.01, n_estimators=3000, max_bin=125, bagging_fraction=0.8,\n",
    "                     bagging_freq=5, bagging_seed=6, feature_fraction=0.2, feature_fraction_seed=6,verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model pipelines are built, I'll compare the scores (lower is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression average RMSE:\n",
      "0.12895556451052964\n",
      "---\n",
      "Lasso regression average RMSE:\n",
      "0.1294129036344291\n",
      "---\n",
      "ElasticNet regression average RMSE:\n",
      "0.1288794920384742\n",
      "---\n",
      "XGBoost regression average RMSE:\n",
      "0.1139048586311368\n",
      "---\n",
      "LGBM regression average RMSE:\n",
      "0.10985568523322146\n"
     ]
    }
   ],
   "source": [
    "# Print the average cross validation RMSE for each model\n",
    "print('Ridge regression average RMSE:')\n",
    "print(cv_rmse(rr, preproc_train, train_y).mean())\n",
    "print('---')\n",
    "\n",
    "print('Lasso regression average RMSE:')\n",
    "print(cv_rmse(lasso, preproc_train, train_y).mean())\n",
    "print('---')\n",
    "      \n",
    "print('ElasticNet regression average RMSE:')\n",
    "print(cv_rmse(enet, preproc_train, train_y).mean())\n",
    "print('---')\n",
    "      \n",
    "print('XGBoost regression average RMSE:')\n",
    "print(cv_rmse(xgb, preproc_train, train_y).mean())\n",
    "print('---')\n",
    "\n",
    "print('LGBM regression average RMSE:')\n",
    "print(cv_rmse(lgbm, preproc_train, train_y).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are fit and the scores all look pretty good. LGBM gave me the best results so I'm going to use that as my secondary regressor and use all the models in my regression stack.\n",
    "\n",
    "I'll build my regression stack and try it out on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack RMSE on test:\n",
      "0.0035647909599203827\n"
     ]
    }
   ],
   "source": [
    "stack = StackingCVRegressor(regressors=[rr, lasso, enet, xgb, lgbm], meta_regressor=lgbm,\n",
    "                           use_features_in_secondary=True)\n",
    "\n",
    "stack.fit(np.array(preproc_train), np.array(train_y))\n",
    "stack_pred = stack.predict(np.array(preproc_train))\n",
    "\n",
    "print(\"Stack RMSE on test:\")\n",
    "print(mean_squared_error(train_y, stack_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, fit the test data, create the submission csv and submit. Make sure to add the file path to where you would like the submission stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_test_pred = stack.predict(np.array(preproc_test))\n",
    "\n",
    "predictions = np.exp(stack_test_pred)\n",
    "\n",
    "results = pd.DataFrame({'Id': np.arange(1461, 2920), 'SalePrice': predictions})\n",
    "\n",
    "results.to_csv('.../submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
